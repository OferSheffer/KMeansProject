2. Consider reducing CUDA "diameter in blocks" load times by loading exact block data into GPU.

3. CUDA resource review (for max occupancy): 
 What do I do about this Registers per thread reccommendation?

****   CUDA Occupancy calculator   ****
		1.) Select Compute Capability (click):	5.0
		Registers Per Thread	32                            !!!!!
--------------------
		1.) Select Compute Capability (click):	2.0
		Registers Per Thread	16/20                            !!!!!
		
--maxrregcount for a hard limit. Usually it will result in more spilling to local memory

4. Got double value from 2 streams. Got double value from 2 blocks.
   Not getting x4 value from using both. Occupancy 50% with SM2 appearing to have no work (My Maxwell).

Why are 2 streams almost the same run-time as 8?
Big impact! less blocks: rework to allow blocks to do more work? (1 kernel now does 2 by 2)

Later: use helper_cuda.h: macros getLastCudaError & checkCudaErrors (See the samples)

Later: less if(numprocs) for master only

Later:
//TODO: use MASTER GPU to asynchronously run first job and poll for completion to give new jobs
	/*
	//async initializations for MASTER
	cudaEvent_t myJobIsDone;
	cudaStatus = cudaEventCreateWithFlags(&myJobIsDone, cudaEventDisableTiming); EVENT_ERROR;
	cudaEventDestroy(myJobIsDone); EVENT_ERROR;


	//cudaMemcpyAsync(d_a, a, nbytes, cudaMemcpyHostToDevice, 0);
	//kDiamBlockWithCuda << <1, THREADS_PER_BLOCK, SharedMemBytes >> > (d_kDiameters, ksize, d_xya, d_pka, N, 0, 0);
	//cudaMemcpyAsync(a, d_a, nbytes, cudaMemcpyDeviceToHost, 0);
	//cudaEventRecord(myJobIsDone, 0);
	//
	//while (cudaEventQuery(stop) == cudaErrorNotReady) {
	//TODO:
	//non-blocking recv from slaves;
	// }
	*/

Later:
AtomicMax: if (*address >= value) // TODO: bottleneck? malloc locally per stream / SM?
