2. Reduce CUDA "diameter in blocks" load times by loading exact block data into GPU.
2.1. am I loading the info many times? or just once at the beginning
2.2. am I unloading all the info many times?
-- perhaps its ok to load all the data at the beginning
-- but then write out only the relevant data to its proper location
-- am I writing out data to a location or just the KDiameter-values?

4. consider merging operations on the Kernel
   (maybe load more data and run it - 
    3+ blocks at a time instead of 2)

6. CUDA resource review (for max occupancy):
****   CUDA Occupancy calculator   ****
		1.) Select Compute Capability (click):	5.0
		1.b) Select Shared Memory Size Config (bytes)	65536
		1.c) Select Global Load Caching Mode	L1+L2 (ca)
	
		2.) Enter your resource usage:	
		Threads Per Block	1024
		Registers Per Thread	32
		Shared Memory Per Block (bytes)	2048
	
		(Don't edit anything below this line)	
	
		3.) GPU Occupancy Data is displayed here and in the graphs:	
		Active Threads per Multiprocessor	2048
		Active Warps per Multiprocessor	64
		Active Thread Blocks per Multiprocessor	2
		Occupancy of each Multiprocessor	100%

--------------------
		1.) Select Compute Capability (click):	2.0
		1.b) Select Shared Memory Size Config (bytes)	65536
		1.c) Select Global Load Caching Mode	L1+L2 (ca)
	
		2.) Enter your resource usage:	
		Threads Per Block	512
		Registers Per Thread	16
		Shared Memory Per Block (bytes)	1024
	
		(Don't edit anything below this line)	
	
		3.) GPU Occupancy Data is displayed here and in the graphs:	
		Active Threads per Multiprocessor	1536
		Active Warps per Multiprocessor	48
		Active Thread Blocks per Multiprocessor	3
		Occupancy of each Multiprocessor	100%

7. Asynchronous launches - reivew material for further improvement.

8. Compute Visual Profiler (CUDA Toolkit) -- 
	find out how many registers your kernel is using
	get "registers per work item" values

9. Even More info
-cl-nv-verbose (OpenCL)
output can be fetched with clGetProgramBuildInfo (CL_PROGRAM_BUILD_LOG).
ptxas info    : Used 16 registers, 36+8 bytes smem, 180 bytes cmem[1]

10. The number of registers available per thread is equal to (by Mark Harris):
N_registersPerMultiprocessor / CEIL(N_concurrentBlocks*N_threadsPerBlock, 64)
100% occupancy really implies a 10 registers/thread limit. - nogradi + Mark (2007)

11. Exact register usages (avidday):
 Pass the -Xptxas="-v" option to nvcc, and the compiler will emit the exact
register usages of the compiled kernel. It is impossible to estimate register
usage from uncompiled C code - the compiler and assembler uses very complex and
aggressive optimization strategies that include code reordering, register re-use,
spilling to local memory, dead code removal, result computation during compilation,
function in-lining and a whole bunch of other stuff.  --maxrregcount option which
will provide a hard limit on how many registers the assembler will try and use for
the kernel. Usually it will result in more spilling to local memory


